<!DOCTYPE html><html lang=en><head><title>Why We Are Investigating the Biases of Artificial Intelligence | ThoughtWorks Arts Residency</title><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width, initial-scale=1.0"><meta name=Description content="ThoughtWorks Arts has an open call out now for artists and technologists investigating the implications of Artificial Intelligence for society today."><meta name=twitter:card content=summary_large_image><meta name=twitter:site content=@tw_arts><meta name=twitter:creator content=@tw_arts><meta property=og:url content="https://thoughtworksarts.io/blog/why-we-are-investigating-biases-artificial-intelligence/"><meta property=og:title content="Why We Are Investigating the Biases of Artificial Intelligence | ThoughtWorks Arts Residency"><meta property=og:image content=https://thoughtworksarts.io/images/posts/2017-05-17-why-we-are-investigating-biases-artificial-intelligence/message.97d6.jpg><meta property=og:description content="ThoughtWorks Arts has an open call out now for artists and technologists investigating the implications of Artificial Intelligence for society today."><link href=//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css rel=stylesheet><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,700,400italic,700italic" rel=stylesheet type=text/css><link rel=canonical href="https://thoughtworksarts.io/blog/why-we-are-investigating-biases-artificial-intelligence/"><link rel=stylesheet href=/stylesheets/style.b3cd.css><!--[if lt IE 9]>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.2/html5shiv-printshiv.min.js"></script>
    <![endif]--><link rel="shortcut icon" href=/images/favicon.ico></head><body id=blog class=content-page><header role=banner class=flex-col><section id=logonav><h1>ThoughtWorks Arts Residency</h1><a href="/" class=logo><img src=/images/twartsresidency.c173.png alt="ThoughtWorks Arts Residency"></a><nav role=navigation><h2>Navigation</h2><a id=menu-button href=#><i class="fa fa-bars"></i> <i class="fa fa-times"></i></a><ul><li><a href="/program/" class=program>Program</a></li><li><a href="/residents/" class=residents>Residents</a></li><li><a href="/projects/" class=projects>Projects</a></li><li><a href="/blog/" class=blog>Blog</a></li></ul></nav></section><figure id=image-splash class=bottom></figure></header><main><section><header><h1>Blog</h1></header><article role=article itemscope itemtype=http://schema.org/BlogPosting><header><h1>Why We Are Investigating the Biases of Artificial Intelligence</h1><div class=widgets><ul class=social><li><a href="http://twitter.com/share?text=Why%20We%20Are%20Investigating%20the%20Biases%20of%20Artificial%20Intelligence&amp;url=http://thoughtworksarts.io/blog/why-we-are-investigating-biases-artificial-intelligence/&amp;via=tw_arts"><i class="fa fa-twitter"></i></a></li><li><a href="http://www.facebook.com/sharer/sharer.php?title=Why%20We%20Are%20Investigating%20the%20Biases%20of%20Artificial%20Intelligence&amp;u=http://thoughtworksarts.io/blog/why-we-are-investigating-biases-artificial-intelligence/"><i class="fa fa-facebook"></i></a></li><li><a href="http://www.tumblr.com/share?v=3&amp;t=Why%20We%20Are%20Investigating%20the%20Biases%20of%20Artificial%20Intelligence&amp;u=http://thoughtworksarts.io/blog/why-we-are-investigating-biases-artificial-intelligence/"><i class="fa fa-tumblr"></i></a></li></ul><figure><a href="/bio/andrew-mcwilliams/"><img src=/images/people/andrew-mcwilliams.e3dd.png alt="Andrew McWilliams"></a> <a href="/bio/ellen-pearlman/"><img src=/images/people/ellen-pearlman.0a57.png alt="Ellen Pearlman"></a><figcaption>Posted by the Residency Directors<br>Monday, 15 May 2017</figcaption></figure></div></header><div class=text-content><p>ThoughtWorks Arts has an <a href="https://thoughtworksarts.io/open-call/2017-implications-of-ai/">open call out now</a> for artists and technologists investigating the implications of Artificial Intelligence for society today.</p><figure><img src=/images/posts/2017-05-17-why-we-are-investigating-biases-artificial-intelligence/message.97d6.jpg><figcaption>Image by <a href="https://www.flickr.com/photos/rpmarks/32144425053/">Roger Marks</a></figcaption></figure><p>AI has incredible potential to automate all kinds of decision-making, and revolutionize industries. However, because of the way in which AI systems are trained, they can also automate and amplify human biases in ways their designers do not intend.</p><!--excerpt-ends--><p>Numerous examples have recently emerged of automated bias in action, suggesting that AI has already permeated into the fabric of our daily lives, and that we are now subject to new forms of pervasive, systemic bias. As our previous resident Heather Dewey-Hagborg <a href="https://thenewinquiry.com/sci-fi-crime-drama-with-a-strong-black-lead/">pointed out</a>, when decisions are made by computers and not humans, they have a false air of objectivity surrounding them.</p><h2>Many facets</h2><p>If you sift through a selection of recent articles on AI, you&rsquo;ll find a dizzying mix of topics. You&rsquo;ll see self-driving cars, Amazon Alexa, industry-specific application analyses, startups and investment news, labor market and looming job loss, often accompanied by pictures of the Terminator or other science fiction movie characters.</p><p>You&rsquo;ll also find articles predicting either dystopic futures, or the technical &lsquo;singularity&rsquo;. The singularity is the moment when AI-based systems, locked in runaway self-improvement cycles, cause an intelligence explosion in which computers far surpass the intelligence of human beings.</p><p>These are important topics, but the actual problems of codification of systemic bias is happening right now all around us. It is also not well understood. This is why our fall 2017 residency cycle will be aimed to tackle this subject.</p><h2>Automated bias in action</h2><p>In 2016, Julia Angwin et. al., published <a href=https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing>an analysis of the risk scores</a> assigned to more than 7,000 people arrested in Broward County, Florida. In many US States, scores like this are used by judges during prison sentencing.</p><p>The study found that black defendants who did not re-offend over a two-year period were almost twice as likely to be misclassified as high risk than white people. Conversely, white defendants were mistakenly labeled low risk almost twice as often as black re-offenders.</p><p>This was not an effect that the designers of the system intended, but more likely a product of the way the system was trained. Further, it is not clear where accountability lies in AI systems, and it is <a href="https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/">not possible for the algorithms</a> to provide a rationale for their decisions.</p><h2>AI Now</h2><p>In 2016, Meredith Whittaker and Kate Crawford founded a new independent research initiative called <a href="https://artificialintelligencenow.com/">AI Now</a>. This initiative is intended as a contribution to illuminate <a href=http://www.nature.com/news/there-is-a-blind-spot-in-ai-research-1.20805>blind spots in AI research</a>, and investigate the current implications on industry, society, and individuals.</p><p>Meredith contributed to the framing of our open call, and we intend to keep the residency connected to the AI Now initiative as it progresses.</p><figure class=video><iframe src=https://www.youtube.com/embed/ZsP6n06zKFg frameborder=0 allowfullscreen></iframe></figure><p>In 2016, AI Now organized a White House symposium to spark cross-disciplinary dialog. All of the presentation recordings <a href="https://www.youtube.com/playlist?list=PLsHf1QGJz7usWgjBKoZIoJrYugNWSDQDK">are archived online</a>. Following the symposium, AI Now published <a href=https://artificialintelligencenow.com/media/documents/AINowSummaryReport_3_RpmwKHu.pdf>this report</a> which analyses and makes recommendations across four subject areas: social inequality, labor, healthcare and ethical responsibility.</p><h2>The role of the artist</h2><p>We have left the call open-ended, to allow artists to surprise us with their intentions to address these complex and difficult issues. As this is certainly an international issue, we have opened up this call to the broader global community so we can receive diverse perspectives.</p><p>We look forward to receiving applications and see a lot of potential for a project in this area of inquiry. Applications are due by the deadline of June 8.</p></div></article><div class=progress><a href="/blog/" class="blog forwards">View all posts</a></div></section></main><footer><div class=subscribe><form class=newsletter-form action=https://tinyletter.com/thoughtworksarts method=post target=popupwindow onsubmit="window.open('https://tinyletter.com/thoughtworksarts', 'popupwindow', 'scrollbars=yes,width=800,height=600');return true"><label for=tlemail>Keep up to date with residency program news:</label><input type=email name=email id=tlemail value="your email" class=faded><input type=hidden value=1 name=embed><input type=submit value=Subscribe id=tlsubmit></form></div><ul class=social><li><a href=https://twitter.com/tw_arts><i class="fa fa-twitter" id=twitter></i></a></li><li><a href="https://www.instagram.com/thoughtworksarts/"><i class="fa fa-instagram"></i></a></li><li><a href=https://github.com/thoughtworksresidency><i class="fa fa-github"></i></a></li></ul><ul class=notices><li><a href=/newsletters>Newsletter Archive</a></li><li><a href=https://www.thoughtworks.com/privacy-policy>Privacy Policy</a></li></ul></footer><script src=/javascript/script.a5cc.js></script></body></html>